import streamlit as st
import pandas as pd
import plotly.express as px
import duckdb
import plotly.graph_objects as go
#è®¾ç½®é¡µé¢æ ‡ç­¾ 
st.set_page_config(page_title="Amazon Analyzer", layout="wide")
# ==========================================
# å…¨é‡è¯­è¨€è¯åº“ (Translation Dictionary)
# ==========================================
LANG_DICT = {
    "zh": {
        "title": "ğŸ“¦ äºšé©¬é€Šçˆ†æ¬¾åˆ†æå™¨ v0.9 (çœŸå®æ•°æ®ç‰ˆ)",
        "guide_title": "ğŸ“– ä½¿ç”¨æŒ‡å—ä¸æ•°æ®è§„èŒƒ (å¿…è¯»)",
        "guide_usage": "æœ¬ç³»ç»Ÿé€šè¿‡**æ–‡ä»¶åå…³é”®å­—**è‡ªåŠ¨åˆ†ç±»ã€‚è¯·ç¡®ä¿æ–‡ä»¶ååŒ…å«ï¼š`sales` (é”€å”®), `traffic` (æµé‡), `ad` (å¹¿å‘Š), `product` (äº§å“), `inventory` (åº“å­˜)ã€‚",
        "guide_table": {
            "type": ["é”€å”®è¡¨", "æµé‡è¡¨", "å¹¿å‘Šè¡¨", "äº§å“ä¿¡æ¯è¡¨", "åº“å­˜è¡¨"],
            "cols": [
                "Date, SKU, Amount, Unit_Cost,Shipping_Fee", 
                "Date, SKU, Sessions, Impressions, Clicks",  # <--- é‡ç‚¹ï¼šåŠ äº†æ›å…‰å’Œç‚¹å‡»
                "SKU, Spend (æˆ– Cost)", 
                "SKU, Real_FBA_Fee, Weight",
                "SKU, Quantity_Available" # <--- æ–°å¢ï¼šåº“å­˜è¡¨
            ],
            "func": ["è®¡ç®—æ¯›åˆ©/å‡€åˆ©", "è®¡ç®—CTR/CVR/æ¼æ–—", "è¯Šæ–­å¹¿å‘Š/ROAS", "ç²¾å‡†è¿è´¹è®¡ç®—", "æ™ºèƒ½è¡¥è´§å»ºè®®"]
        },
        "guide_table_headers": ["æŠ¥è¡¨ç±»å‹", "æ ¸å¿ƒå¿…éœ€åˆ—å", "å¯¹åº”åˆ†æåŠŸèƒ½"], 
        "upload_label": "ä¸Šä¼ æŠ¥è¡¨ (æ”¯æŒå¤šé€‰æ‹–å…¥)",
        "sidebar_header": "ğŸ“Š æ§åˆ¶é¢æ¿",
        "lang_select": "é€‰æ‹©è¯­è¨€",
        "ad_setting": "æ‚è´¹è®¾ç½®",
        "other_costs": "å…¶ä»–æ‚è´¹ (æ€»é¢åˆ†æ‘Š)",
        "metric_sales": "ğŸ’° æ€»é”€å”®é¢",
        "metric_qty": "ğŸ“¦ æ€»é”€é‡",
        "metric_profit": "æœ€ç»ˆå‡€åˆ©æ¶¦",
        "metric_ad": "ğŸ”¥ çœŸå®å¹¿å‘Šè´¹",
        "metric_storage": "ğŸ“¦ é¢„ä¼°æ€»ä»“å‚¨è´¹",
        "storage_help": "ğŸ’¡ ä»“å‚¨è´¹æ ¹æ® 1-9æœˆ($0.87/cuft) å’Œ 10-12æœˆ($2.40/cuft) åŠ¨æ€è®¡ç®—ã€‚",
        "chart_trend_title": "ğŸ“ˆ æ¯æ—¥é”€å”®è¶‹åŠ¿",
        "chart_pie_title": "ğŸ• SKU é”€å”®å æ¯”",
        "table_title": "ğŸ† çœŸå®åˆ©æ¶¦æ¦œå•",
        "ai_advice": "ğŸ¤– ç»è¥å»ºè®®",
        "unit": "ä»¶",
        "sign": "Â¥",
        "report_header": "æœ¬æœŸç»è¥æŠ¥å‘Š",
        "error_cost": "âŒ ä½ çš„è¡¨æ ¼ç¼ºå°‘ 'Unit_Cost' (æˆæœ¬) åˆ—ï¼",
        "filter_header":"ğŸ” ç­›é€‰æ¡ä»¶",
        "select_date":"è¯·é€‰æ‹©æ—¥æœŸ",
        "vampire_title": "ğŸ§›â€â™‚ï¸ å¹¿å‘Šå¸è¡€é¬¼è¯Šæ–­ (åŸºäºçœŸå®èŠ±è´¹)",
        "vampire_help": "âš ï¸ å‘ç° {} ä¸ª SKU å¹¿å‘Šæ­£åœ¨äºé’±ï¼ˆçœŸå® ROAS ä½äºä¿æœ¬çº¿ï¼‰ï¼",
        "roas_label": "çœŸå® ROAS",
        "recommend_action": "ğŸ’¡ è´¢åŠ¡å°è´´å£«ï¼šå½“ [çœŸå® ROAS] < [ä¿æœ¬ ROAS] æ—¶ï¼Œæ‚¨çš„æ¯ä¸€ç¬”å¹¿å‘ŠæŠ•å…¥éƒ½åœ¨ä¾µèš€äº§å“åˆ©æ¶¦ã€‚",
        "metric_cvr": "è½¬åŒ–ç‡ (CVR)",
        "error_no_sales": "âŒ è¯·è‡³å°‘ä¸Šä¼ ä¸€ä»½é”€å”®æŠ¥è¡¨ï¼",
        "page_title": "äºšé©¬é€Šæ•°æ®çœ‹æ¿",
        "download_btn": "ğŸ“¥ ä¸‹è½½æ¦œå•æ•°æ® (CSV)",
        "error_general": "âŒ å‘ç”Ÿé”™è¯¯",
        "upload_info": "ğŸ‘† è¯·å‚è€ƒä¸Šæ–¹æŒ‡å—å¹¶ä¸Šä¼ æŠ¥è¡¨ä»¥è·å¾—æ•°æ®",
        "filter_all": "ğŸ“… æ‰€æœ‰æ—¥æœŸ",
        "advice_danger": "âš ï¸ é£é™©é¢„è­¦ï¼šå‡€åˆ©ä¸ºè´Ÿï¼è¯·æ£€æŸ¥å¹¿å‘ŠæŠ•äº§æ¯”ã€‚",
        "advice_good": "âœ… ç»è¥ç¨³å¥ï¼šæœ‰ä¸€å®šåˆ©æ¶¦ç©ºé—´ã€‚",
        "advice_best": "ğŸš€ åˆ©æ¶¦ä¸°åšï¼šè¯¥äº§å“è¡¨ç°ä¼˜å¼‚ï¼",
        "warn_no_ad": "âš ï¸ æœªæ£€æµ‹åˆ°å¹¿å‘ŠæŠ¥è¡¨ï¼å¹¿å‘Šè´¹ç›®å‰æ˜¾ç¤ºä¸º 0ã€‚",
        "col_sku": "SKU",
        "col_ad_spend": "å¹¿å‘Šè´¹æ”¯å‡º",
        "col_be_roas": "ä¿æœ¬ ROAS",
        "vampire_safe": "âœ… è¡¨ç°ä¼˜ç§€ï¼æœªå‘ç°å¹¿å‘Šå¸è¡€é¬¼ã€‚",
        "vampire_none": "ğŸ’¡ æš‚æ— å¹¿å‘Šæ•°æ®ï¼Œè¯·ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨ã€‚",
        "vampire_no_spend": "â„¹ï¸ å½“å‰ç­›é€‰æ—¶æ®µå†…æ— å¹¿å‘ŠèŠ±è´¹ã€‚",
        "tpl_download_section": "ğŸ“‚ **ä¸‹è½½æ ‡å‡†æ¨¡æ¿ (å¡«å…¥æ•°æ®åä¸Šä¼ )ï¼š**",
        "tpl_sales": "ğŸ“Š é”€å”®æ¨¡æ¿",
        "tpl_traffic": "ğŸŒ æµé‡æ¨¡æ¿ (å«æ›å…‰ç‚¹å‡»)",
        "tpl_ad": "ğŸ”¥ å¹¿å‘Šæ¨¡æ¿",
        "tpl_info": "ğŸ“¦ ä¿¡æ¯æ¨¡æ¿",
        "tpl_inv": "ğŸ“¦ åº“å­˜æ¨¡æ¿",
        "tpl_tip": "ğŸ’¡ **å°å»ºè®®**ï¼šæ‚¨å¯ä»¥ç›´æ¥ä¸‹è½½æ¨¡æ¿ï¼Œå¡«å…¥æ•°æ®å³å¯è¯†åˆ«ã€‚",
        "metric_v": "ğŸš€ æ—¥å‡é”€é‡ (14å¤©)",
        "metric_days": "âŒ› å¯å”®å¤©æ•°",
        "restock_title": "ğŸ“Š æ™ºèƒ½è¡¥è´§å»ºè®® (åŸºäº14å¤©é”€é‡åŠ¨æ€)",
        "col_inv": "å½“å‰å¯ç”¨åº“å­˜",
        "col_suggest": "å»ºè®®è¡¥è´§é‡",
        "target_days_label": "ç›®æ ‡åº“å­˜è¦†ç›–å¤©æ•°",
        "error_inv_col" :  "âŒ åº“å­˜è¡¨ä¸­ç¼ºå°‘å…³é”®åˆ—: Quantity_Available",

        # === æ¼æ–—å›¾ä¸è¯Šæ–­éƒ¨åˆ† ===
        "funnel_title": "ğŸ“¢ å…¨åº—æµé‡è½¬åŒ–æ¼æ–— (Funnel Analysis)",
        "funnel_stages": ["æ›å…‰é‡ (Impressions)", "ç‚¹å‡»é‡ (Clicks)", "è®¿å®¢æ•° (Sessions)", "é”€é‡ (Units)"],
        "funnel_chart_title": "æµé‡ -> é”€é‡ è½¬åŒ–é“¾è·¯",
        "diag_title": "ğŸ•µï¸â€â™‚ï¸ äºšé©¬é€Šè¿è¥ä½“æ£€æŠ¥å‘Šï¼š",
        "diag_ctr_bad": "âŒ **ä¸»å›¾æ€¥éœ€ä¼˜åŒ– (CTR = {:.2%})**ï¼šä½äº 0.3% çš„åŠæ ¼çº¿ã€‚å»ºè®®ï¼šé‡æ‹ä¸»å›¾ï¼Œæˆ–æ£€æŸ¥å¹¿å‘Šè¯æ˜¯å¦å¤ªæ³›ã€‚",
        "diag_ctr_mid": "âš ï¸ **ä¸»å›¾è¡¨ç°å¹³å¹³ (CTR = {:.2%})**ï¼šåœ¨è¡Œä¸šå¹³å‡æ°´å¹³ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚",
        "diag_ctr_good": "âœ… **ä¸»å›¾å¾ˆæœ‰å¸å¼•åŠ› (CTR = {:.2%})**ï¼šè¡¨ç°ä¼˜å¼‚ï¼",
        "diag_click_bad": "âš ï¸ **æ— æ•ˆç‚¹å‡»è¿‡å¤š (æœ‰æ•ˆç‡ {:.0%})**ï¼šå¯èƒ½å­˜åœ¨æ¶æ„ç‚¹å‡»ï¼Œæˆ–ç½‘é¡µåŠ è½½å¤ªæ…¢ã€‚",
        "diag_cvr_bad": "âŒ **è½¬åŒ–ç‡åä½ (CVR = {:.2%})**ï¼šæµé‡è¿›æ¥äº†ç•™ä¸ä½ã€‚å»ºè®®ï¼šä¼˜åŒ–äº”ç‚¹æè¿°ã€å¢åŠ å¥½è¯„ã€æ£€æŸ¥ä»·æ ¼ä¼˜åŠ¿ã€‚",
        "diag_cvr_mid": "â„¹ï¸ **è½¬åŒ–ç‡æ­£å¸¸ (CVR = {:.2%})**ï¼šç¬¦åˆå¤§å¤šæ•°ç±»ç›®æ ‡å‡†ã€‚",
        "diag_cvr_good": "ğŸš€ **çˆ†æ¬¾è½¬åŒ–ç‡ (CVR = {:.2%})**ï¼šè½¬åŒ–éå¸¸æ£’ï¼åªè¦åŠ å¤§æµé‡å°±èƒ½èµ·é£ã€‚"
    },

    "en": {
        "title": "ğŸ“¦ Amazon Analyzer v0.9",
        "guide_title": "ğŸ“– Usage Guide & Data Standards",
        "guide_usage": "System identifies files by **keywords**: `sales`, `traffic`, `ad`, `product`, `inventory`.",
        "guide_table": {
            "type": ["Sales", "Traffic", "Ads", "Info", "Inventory"],
            "cols": [
                "Date, SKU, Amount, Unit_Cost,Shipping_Fee", 
                "Date, SKU, Sessions, Impressions, Clicks", 
                "SKU, Spend (or Cost)", 
                "SKU, Real_FBA_Fee, Weight",
                "SKU, Quantity_Available"
            ],
            "func": ["Profit Analysis", "CTR/CVR/Funnel", "Ad Diagnosis", "Shipping Calc", "Restock Plan"]
        },
        "guide_table_headers": ["Type", "Required Columns", "Features"],
        "upload_label": "Upload Reports (Drag & Drop)",
        "sidebar_header": "Dashboard",
        "lang_select": "Language",
        "ad_setting": "Overhead Costs",
        "other_costs": "Other Costs",
        "metric_sales": "ğŸ’° Revenue",
        "metric_qty": "ğŸ“¦ Volume",
        "metric_profit": "Net Profit",
        "metric_ad": "ğŸ”¥ Ad Spend",
        "metric_storage": "ğŸ“¦ Est. Storage Fee",
        "storage_help": "ğŸ’¡ Jan-Sep($0.87) & Oct-Dec($2.40) per cuft.",
        "chart_trend_title": "ğŸ“ˆ Daily Sales Trend",
        "chart_pie_title": "ğŸ• SKU Distribution",
        "table_title": "ğŸ† Profit Ranking",
        "ai_advice": "ğŸ¤– AI Insights",
        "unit": "units",
        "sign": "$",
        "report_header": "Performance Report",
        "error_cost": "âŒ Missing 'Unit_Cost'!",
        "filter_header": "ğŸ” Filters",
        "select_date":"Select Date",
        "vampire_title": "ğŸ§›â€â™‚ï¸ Ad Vampire Detection",
        "vampire_help": "âš ï¸ Found {} SKUs losing money!",
        "roas_label": "Real ROAS",
        "recommend_action": "ğŸ’¡ Finance Tip: If Actual ROAS < BE ROAS, ads are losing money.",
        "metric_cvr": "Conv. Rate (CVR)",
        "error_no_sales": "âŒ No Sales Report!",
        "page_title": "Amazon Dashboard",
        "download_btn": "ğŸ“¥ Download CSV",
        "error_general": "âŒ Error",
        "upload_info": "ğŸ‘† Upload reports to start",
        "filter_all": "ğŸ“… All Dates",
        "advice_danger": "âš ï¸ Warning: Negative Profit!",
        "advice_good": "âœ… Healthy Margin.",
        "advice_best": "ğŸš€ Excellent Profit!",
        "warn_no_ad": "âš ï¸ No Ad Report detected!",
        "col_sku": "SKU",
        "col_ad_spend": "Ad Spend",
        "col_be_roas": "BE ROAS",
        "vampire_safe": "âœ… Excellent! No Vampires.",
        "vampire_none": "ğŸ’¡ No ad data.",
        "vampire_no_spend": "â„¹ï¸ No ad spend in period.",
        "tpl_download_section": "ğŸ“‚ **Download Templates:**",
        "tpl_sales": "ğŸ“Š Sales Tpl",
        "tpl_traffic": "ğŸŒ Traffic Tpl",
        "tpl_ad": "ğŸ”¥ Ad Tpl",
        "tpl_info": "ğŸ“¦ Info Tpl",
        "tpl_inv": "ğŸ“¦ Inv Tpl",
        "tpl_tip": "ğŸ’¡ **Tip**: Use templates for best results.",
        "metric_v": "ğŸš€ Daily Velocity",
        "metric_days": "âŒ› Days Left",
        "restock_title": "ğŸ“Š Smart Restock Plan",
        "col_inv": "Available Stock",
        "col_suggest": "Suggest Qty",
        "target_days_label": "Target Stock Days",
        "error_inv_col": "âŒ Missing column: Quantity_Available",

        # === Funnel & Diagnosis ===
        "funnel_title": "ğŸ“¢ Storewide Conversion Funnel",
        "funnel_stages": ["Impressions", "Clicks", "Sessions", "Units Sold"],
        "funnel_chart_title": "Conversion Path: Impressions -> Sales",
        "diag_title": "ğŸ•µï¸â€â™‚ï¸ Amazon Health Check",
        "diag_ctr_bad": "âŒ **Critical CTR ({:.2%})**: Below 0.3%. Action: Check main image.",
        "diag_ctr_mid": "âš ï¸ **Average CTR ({:.2%})**: Acceptable but room for improvement.",
        "diag_ctr_good": "âœ… **Excellent CTR ({:.2%})**: Your main image is working well!",
        "diag_click_bad": "âš ï¸ **Low Traffic Quality ({:.0%} valid)**: Potential bot clicks or slow page load.",
        "diag_cvr_bad": "âŒ **Low CVR ({:.2%})**: Traffic is wasted. Action: Optimize listing or price.",
        "diag_cvr_mid": "â„¹ï¸ **Normal CVR ({:.2%})**: Within industry standards.",
        "diag_cvr_good": "ğŸš€ **High CVR ({:.2%})**: Potential Best Seller! Scale up your ads."
    }
}
# ==========================================
# 1. æŠ€èƒ½åŒº (Functions)
# ==========================================
#ä¸Šä¼ æ–‡ä»¶
@st.cache_data
def load_data(file):
    if file.name.endswith('.csv'):
        try:
            return pd.read_csv(file)
        except:
            file.seek(0)
            return pd.read_csv(file, encoding='gbk')
    else:
        return pd.read_excel(file)
#ç»˜å›¾
def plot_charts(df,text):
    # 1. æŠ˜çº¿å›¾
    daily_trend = df.groupby('Date')['Total_Sales'].sum().reset_index()
    fig_trend = px.line(
        daily_trend, 
        x='Date', 
        y='Total_Sales',
        title=text["chart_trend_title"],
        markers=True, 
    )
    
    # 2. ç”œç”œåœˆå›¾ (Pie Chart,text)
    sku_distribution = df.groupby('SKU')['Total_Sales'].sum().reset_index()
    fig_pie = px.pie(
        sku_distribution, 
        values='Total_Sales', 
        names='SKU', 
        title=text["chart_pie_title"],
        hole=0.3, # è¿™é‡Œçš„æ•°å­— 0.3 æ§åˆ¶ä¸­é—´é‚£ä¸ªæ´çš„å¤§å°
    )
    
    return fig_trend, fig_pie

#åˆ©æ¶¦ç‡è‡ªåŠ¨ç”Ÿæˆå»ºè®®
def generate_summary(revenue,profit,margin,text):
    summary=f'{text["report_header"]}\n\n'
    summary+=f'{text["metric_sales"]}: {text["sign"]}{revenue:,.2f}ã€‚\n'
    summary+=f'{text["metric_profit"]}: {text["sign"]}{profit:,.2f}({margin*100:.1f}%)ã€‚\n\n'
    if margin < 0.1:
        summary += text['advice_danger']
    elif margin < 0.3:
        summary += text['advice_good']
    else:
        summary += text['advice_best']
    return summary
#æ¸…æ´—æ•°æ®
def clean_data(df):
    df.columns = [str(c).strip() for c in df.columns]#å»æ‰æ¯ä¸€åˆ—ä¸¤è¾¹çš„ç©ºæ ¼
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')#å°†æ—¥æœŸè½¬åŒ–ä¸ºç»Ÿä¸€æ ¼å¼ï¼Œé‡åˆ°åƒåœ¾æ•°æ®å¼ºåˆ¶è½¬æ¢ä¸ºç©ºå€¼
        df = df.dropna(subset=['Date'])#å°†æ—¥æœŸè¿™åˆ—æœ‰ç©ºå€¼çš„è¡Œä¸¢æ‰
    
    if 'SKU' in df.columns:
        df['SKU'] = df['SKU'].astype(str).str.strip().str.upper()#å°†SKUè¿™ä¸€åˆ—è½¬æ¢æˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œå»æ‰ç©ºæ ¼ï¼Œå…¨éƒ¨å¤§å†™
    
    # ç»Ÿä¸€æ¸…æ´—æ•°å­—åˆ—ï¼Œé˜²æ­¢æŠ¥é”™
    cols_to_numeric = ['Sessions', 'Amount', 'Total_Sales', 'Unit_Cost', 'Shipping_Fee', 'Price', 'Spend', 'SPEND', 'Cost']
    for col in cols_to_numeric:
        if col in df.columns:
            if df[col].dtype == 'object':#å¦‚æœè¡¨å¤´æ˜¯æ–‡æœ¬æˆ–å­—ç¬¦ä¸²æ ¼å¼
                df[col] = df[col].astype(str).str.replace(r'[$,Â¥%\s]', '', regex=True)
                #è½¬æ¢æˆå­—ç¬¦ï¼Œå»æ‰å•ä½ï¼Œregex=True è¡¨ç¤ºå¼€å¯æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ã€‚å®ƒèƒ½è®© Python æ ¹æ®â€˜è§„å¾‹â€™å»åŒ¹é…å­—ç¬¦ï¼Œæ–¹ä¾¿æˆ‘ä¸€æ¬¡æ€§åˆ æ‰æŠ¥è¡¨é‡Œå„ç§ä¹±ä¸ƒå…«ç³Ÿçš„è´§å¸ç¬¦å·å’Œé€—å·ã€‚ 
                #å¢åŠ äº†ä¸€ä¸ª \sï¼Œç”¨æ¥è‡ªåŠ¨å»æ‰æ•°å­—ä¸­é—´å¯èƒ½å­˜åœ¨çš„ç©ºæ ¼ï¼ˆæ¯”å¦‚æŸäº›æŠ¥è¡¨é‡Œçš„ 1 234.00ï¼‰
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)#å°†é‚£ä¸€åˆ—çš„æ ¼å¼è½¬æ¢ä¸ºæ•°å­—ï¼Œè½¬æ¢ä¸äº†çš„èµ‹å€¼0
            
    df = df.drop_duplicates()#å»æ‰é‡å¤è¡Œ
    return df
#è®¡ç®—è¿è´¹
def calculate_fba_fee(weight, length=0, width=0, height=0):
    # 1. è®¡ç®—ä½“ç§¯é‡ (å…¬å¼: L*W*H / 139)
    vol_weight = (length * width * height) / 139
    
    # 2. è®¡è´¹é‡é‡å–ä¸¤è€…æœ€å¤§å€¼ (ä»…é’ˆå¯¹æ ‡å‡†å°ºå¯¸ä»¥ä¸Šçš„è´§ä»¶ï¼Œè¿™é‡Œæˆ‘ä»¬åšé€šç”¨ç®€åŒ–)
    billing_weight = max(weight, vol_weight)
    
    # 3. åŸºç¡€é˜¶æ¢¯é€»è¾‘ (ç»´æŒä½ ä¹‹å‰çš„é€»è¾‘ï¼Œä½†ä½¿ç”¨ billing_weight)
    if billing_weight <= 1:
        return 4.75
    return 4.75 + (billing_weight - 1) * 0.5
#ä¸‰çº§é€»è¾‘è¿ç®—
def get_final_fba(row, fallback_fee):
    if 'Real_FBA_Fee' in row and pd.notnull(row['Real_FBA_Fee']):
        return row['Real_FBA_Fee']
    
    # å¦‚æœæœ‰é•¿å®½é«˜ï¼Œè°ƒç”¨å‡çº§ç‰ˆçš„è®¡ç®—å‡½æ•°
    l = row.get('Length', 0)
    w = row.get('Width', 0)
    h = row.get('Height', 0)
    weight = row.get('Weight', 0)
    
    if weight > 0 or (l*w*h) > 0:
        return calculate_fba_fee(weight, l, w, h)
        
    return fallback_fee
    #ä»“å‚¨è´¹
def calculate_monthly_storage_fee(row):
    """
    è®¡ç®—å•ä¸ªäº§å“çš„æœˆåº¦ä»“å‚¨è´¹é¢„ä¼°
    äºšé©¬é€Šè´¹ç‡å‚è€ƒï¼ˆæ ‡å‡†å°ºå¯¸ï¼‰ï¼š1-9æœˆ $0.87/ç«‹æ–¹è‹±å°ºï¼›10-12æœˆ $2.40/ç«‹æ–¹è‹±å°º
    """
    l = row.get('Length', 0)
    w = row.get('Width', 0)
    h = row.get('Height', 0)
    
    if (l * w * h) <= 0:
        return 0
    
    # 1. è®¡ç®—ä½“ç§¯ï¼ˆç«‹æ–¹è‹±å°ºï¼‰
    volume_cuft = (l * w * h) / 1728
    
    # 2. åˆ¤æ–­æ·¡æ—ºå­£ï¼ˆè·å–æ•°æ®ä¸­çš„æœˆä»½ï¼‰
    # å¦‚æœ row é‡Œæ²¡æœ‰æ—¥æœŸï¼Œé»˜è®¤ç”¨æ·¡å­£è´¹ç‡ï¼Œæˆ–è€…ä» sidebar ä¼ å…¥æœˆä»½
    rate = 0.87 
    if 'Date' in row and pd.notnull(row['Date']):
        month = row['Date'].month
        if month >= 10:
            rate = 2.40
            
    return volume_cuft * rate
# ==========================================
# 2. ä¸»ç¨‹åºåŒº (Main App)
# ==========================================
#è®©ç”¨æˆ·é€‰æ‹©è¯­è¨€
lang_choice=st.sidebar.radio('Language/è¯­è¨€',['ä¸­æ–‡','English'])
lang='zh' if lang_choice=='ä¸­æ–‡' else 'en'
text=LANG_DICT[lang]
#æ ‡é¢˜
st.title(text["title"])
#ReadMe è¯´æ˜æŒ‡å—å’Œæ¨¡æ¿ä¸‹è½½
### èŒä¸šåŒ–ä¿®æ­£ï¼šé›†æˆå››å¤§æ ‡å‡†æ¨¡æ¿ä¸‹è½½ ###
# --- README å¼•å¯¼åŒº (å®Œå…¨å­—å…¸åŒ–ç‰ˆæœ¬) ---
with st.expander(text["guide_title"], expanded=True):
    st.markdown(text["guide_usage"])
    guide_df = pd.DataFrame(text["guide_table"])
    guide_df.columns = text["guide_table_headers"] 
    st.table(guide_df)
    
    st.write(text["tpl_download_section"])
    t1, t2, t3, t4,t5 = st.columns(5)
    
    with t1:
        sales_tpl = pd.DataFrame({
            'Date': ['2026-01-01'], 'SKU': ['SKU-A01'], 'Amount': [10], 
            'Unit_Cost': [5.50], 'Total_Sales': [150.00], 'Price': [15.00]
        }).to_csv(index=False).encode('utf-8-sig')
        st.download_button(text["tpl_sales"], data=sales_tpl, file_name="sales_template.csv")

    with t2:
        traffic_tpl = pd.DataFrame({
            'Date': ['2026-01-01'], 'SKU': ['SKU-A01'], 'Sessions': [100]
        }).to_csv(index=False).encode('utf-8-sig')
        st.download_button(text["tpl_traffic"], data=traffic_tpl, file_name="traffic_template.csv")

    with t3:
        ad_tpl = pd.DataFrame({
            'SKU': ['SKU-A01'], 'Spend': [20.50], 'Impressions': [1000]
        }).to_csv(index=False).encode('utf-8-sig')
        st.download_button(text["tpl_ad"], data=ad_tpl, file_name="ad_template.csv")

    with t4:
        info_tpl = pd.DataFrame({
            'SKU': ['SKU-A01'], 'Product_Name': ['Sample'], 'Weight': [1.2], 'Length':[3],'Width':[2],'Height':[1],
            'Real_FBA_Fee': [4.75], 'Category': ['Home']
        }).to_csv(index=False).encode('utf-8-sig')
        st.download_button(text["tpl_info"], data=info_tpl, file_name="product_info_template.csv")

    with t5: 
        inv_tpl = pd.DataFrame({
            'SKU': ['SKU-A01'], 
            'Quantity_Available': [50], 
            'Quantity_Inbound': [100]  
        }).to_csv(index=False).encode('utf-8-sig')
        st.download_button(text["tpl_inv"], data=inv_tpl, file_name="inventory_template.csv")

    st.info(text["tpl_tip"])

#åŠ è½½æ–‡ä»¶
uploaded_files = st.file_uploader(text["upload_label"], type=['csv', 'xlsx'],accept_multiple_files=True)
if uploaded_files:
    try:
        sales_dfs, traffic_dfs, adv_dfs, product_info_df,inventory_df = [], [], [], None,None

        for file in uploaded_files:
            temp_df=load_data(file)
            f_name = file.name.lower()
            if 'traffic' in f_name:
                traffic_dfs.append(temp_df)
            elif 'product' in f_name:
                product_info_df=temp_df
            elif 'ad' in f_name or 'advertising' in f_name: # è¯†åˆ«å¹¿å‘Šè¡¨
                adv_dfs.append(temp_df)
            elif 'inventory' in f_name or 'stock' in f_name or 'fba_inventory' in f_name:
                inventory_df = temp_df
            else:
                sales_dfs.append(temp_df)
        if not sales_dfs:
            st.warning(text["error_no_sales"])
            st.stop()
        #å¤„ç†é”€å”®æ•°æ®
        df_sales=pd.concat(sales_dfs,ignore_index=True)
        df_sales=clean_data(df_sales)
        # å…ˆå¯¹é”€å”®æ•°æ®æŒ‰å¤©èšåˆï¼ˆé˜²æ­¢ merge æ—¶ Sessions ç¿»å€ï¼‰
        df_sales_daily = df_sales.groupby(['SKU', 'Date']).agg({
            'Amount': 'sum',
            'Total_Sales': 'sum',
            'Unit_Cost': 'first', # å‡è®¾åŒä¸€SKUæˆæœ¬ä¸€è‡´
            'Price': 'mean'
        }).reset_index()
        #å¤„ç†äº§å“ä¿¡æ¯æ•°æ®
        if product_info_df is not None:
            product_info_df = clean_data(product_info_df).drop_duplicates('SKU')
            cols_to_use = product_info_df.columns.difference(df_sales_daily.columns.difference(['SKU']))
            df = pd.merge(df_sales_daily, product_info_df[cols_to_use], on='SKU', how='left')
        else:
            df = df_sales_daily.copy()
        #å¤„ç†æµé‡æ•°æ®
        if traffic_dfs:
            df_traffic_all=pd.concat(traffic_dfs,ignore_index=True)
            df_traffic_all = clean_data(df_traffic_all)
            # 1. LEFT JOIN (å·¦è¿æ¥)ï¼šä»¥é”€å”®è¡¨(df)ä¸ºä¸»ï¼ŒæŠŠæµé‡æ•°æ®(t)æ‹¼è¿‡æ¥ï¼Œä¿è¯åªè¦æœ‰é”€é‡çš„æ•°æ®éƒ½ä¿ç•™ã€‚
            # 2. ON SKU/Dateï¼šå¿…é¡»æ˜¯â€œåŒä¸€ä¸ªäº§å“â€åœ¨â€œåŒä¸€å¤©â€çš„æ•°æ®æ‰åˆå¹¶ï¼Œè¿™æ˜¯åŒé‡ä¿é™©ã€‚
            # 3. COALESCEï¼šå¦‚æœæŸå¤©æ²¡æŠ“åˆ°æµé‡æ•°æ®ï¼Œå¼ºåˆ¶å¡«ä¸º 0ï¼Œé˜²æ­¢åé¢ç®—è½¬åŒ–ç‡(é™¤æ³•)æ—¶æŠ¥é”™ã€‚
            # 4. æŠŠ df è¡¨é‡Œçš„ Order ID, Sales, Units ç­‰æ‰€æœ‰åŸæœ‰å­—æ®µéƒ½æ‹¿è¿‡æ¥ã€‚
            query="""
            SELECT
            df.*,
            COALESCE(t.Sessions, 0) AS Sessions,
            COALESCE(t.Impressions, 0) AS Impressions,
            COALESCE(t.Clicks, 0) AS Clicks
            FROM df
            LEFT JOIN(
            SELECT
            SKU,
            Date,
            SUM(Sessions) AS Sessions,
            SUM(Impressions) AS Impressions,
            SUM(Clicks) AS Clicks
            FROM df_traffic_all
            GROUP BY SKU, Date
            ) AS t
            ON df.SKU = t.SKU AND df.Date = t.Date
            """
            df = duckdb.query(query).df()
        else:
            df['Sessions'] = 0
            df['Impressions'] = 0
            df['Clicks'] = 0
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤´ç¨‹è¿è´¹åˆ—
        if 'Shipping_Fee' not in df.columns:
            df['Shipping_Fee'] = 0
        #æ£€æŸ¥æ˜¯å¦åŒ…å«æˆæœ¬åˆ—
        if 'Unit_Cost' not in df.columns:
            st.error (text["error_cost"])
            st.stop()#åœæ­¢è¿è¡Œ
        #ä¾§è¾¹æ æ‰‹åŠ¨è®¾ç½®ä½£é‡‘å’ŒFBAè´¹è¿˜æœ‰æ‚è´¹
        with st.sidebar.expander(text["ad_setting"]):
            referral_rate=st.slider('Platform Fee(%)',0,30,15)/100
            avg_fba_fee=st.number_input('Avg FBA Fee',value=3.5,step=0.1)
            other_costs = st.sidebar.number_input(text["other_costs"], value=0.0, step=100.0)
        #è®¡ç®—è¿è´¹
        df['FBA_Single'] = df.apply(get_final_fba, axis=1, args=(avg_fba_fee,))
        
        #è®¡ç®—æ€»é”€å”®é¢
        if 'Total_Sales' not in df.columns:
            if 'Price' in df.columns and 'Amount' in df.columns:
                df['Total_Sales'] = df['Price'] * df['Amount']
            else:
                st.error("è¡¨æ ¼ä¸­ç¼ºå°‘ 'Total_Sales' æˆ– 'Price' åˆ—ï¼Œæ— æ³•è®¡ç®—é”€å”®é¢")
        #ä¾§è¾¹æ æ—¥æœŸ
        st.sidebar.header(text["filter_header"])
        df['Date_Only'] = df['Date'].dt.date
        date_list = sorted(df['Date_Only'].unique(), reverse=True)
        all_options = [text["filter_all"]] + date_list
        selected_date = st.sidebar.selectbox(text["select_date"], all_options)
        if selected_date == text["filter_all"]:
            filtered_df = df.copy()
            period_name = text["filter_all"]
        else:
            filtered_df = df[df['Date_Only'] == selected_date].copy()
            period_name = str(selected_date)
        #è®¡ç®—æ ¸å¿ƒæ•°æ®
        filtered_df['Storage_Single'] = filtered_df.apply(calculate_monthly_storage_fee, axis=1)#è®¡ç®—æ¯æœˆä»“å‚¨è´¹
        filtered_df['Storage_Total'] = filtered_df['Storage_Single'] * filtered_df['Amount']#è®¡ç®—æ¯ä¸ªäº§å“ä»“å‚¨è´¹ä¹‹å’Œ
        filtered_df['Ref_Fee'] = filtered_df['Total_Sales'] * referral_rate#å¹³å°ä½£é‡‘
        filtered_df['FBA_Total'] = filtered_df['FBA_Single'] * filtered_df['Amount']#äºšé©¬é€Šè¿è´¹
        filtered_df['Total_Cost'] = filtered_df['Unit_Cost'] * filtered_df['Amount']#å•ä¸ªäº§å“æ€»æˆæœ¬
        filtered_df['Total_Shipping'] = filtered_df['Shipping_Fee'] * filtered_df['Amount']#å…¨éƒ¨å¤´ç¨‹è¿è´¹
        filtered_df['Gross_Profit'] = filtered_df['Total_Sales'] - filtered_df['Ref_Fee'] - filtered_df['FBA_Total'] - filtered_df['Total_Cost']- filtered_df['Total_Shipping'] -filtered_df['Storage_Total']#å•ä¸ªäº§å“æ¯›åˆ©
        sku_group = filtered_df.groupby('SKU').agg({
            'Total_Sales': 'sum',
            'Gross_Profit': 'sum',
            'Amount': 'sum',
            'Sessions': 'sum',
            'Storage_Total': 'sum',
            'Impressions': 'sum',
            'Clicks': 'sum'
        }).reset_index()
        #å¤„ç†çœŸå®å¹¿å‘Šè´¹
        if adv_dfs:
            df_adv_all = pd.concat(adv_dfs, ignore_index=True)
            df_adv_all = clean_data(df_adv_all)

            # å°è¯•æ‰¾ Spend åˆ—
            spend_col = None
            for c in ['Spend', 'SPEND', 'Cost', 'COST']:
                if c in df_adv_all.columns:
                    spend_col = c
                    break
            # å°è¯•æ‰¾ SKU åˆ—
            sku_col = 'SKU'
            if 'Advertised SKU' in df_adv_all.columns and 'SKU' not in df_adv_all.columns:
                df_adv_all = df_adv_all.rename(columns={'Advertised SKU': 'SKU'})
            elif 'ASIN' in df_adv_all.columns and 'SKU' not in df_adv_all.columns:
                 # å¦‚æœåªæœ‰ ASINï¼Œè¿™é‡Œå¯ä»¥æç¤ºç”¨æˆ·ï¼Œä½†æš‚æ—¶æˆ‘ä»¬å‡è®¾æœ‰ SKU
                 pass
            #è®©å¹¿å‘Šè´¹éšä¾§è¾¹æ æ—¥æœŸå˜åŠ¨
            if 'Date' in df_adv_all.columns:
                if selected_date != text["filter_all"]:
                    df_adv_all = df_adv_all[df_adv_all['Date'].dt.date == selected_date]

            if spend_col:
                # èšåˆå¹¿å‘Šè´¹
                sku_adv_agg = df_adv_all.groupby('SKU')[spend_col].sum().reset_index()
                sku_adv_agg.rename(columns={spend_col: 'Real_Ad_Spend'}, inplace=True)
                
                # åˆå¹¶åˆ°ä¸»è¡¨
                sku_group = pd.merge(sku_group, sku_adv_agg, on='SKU', how='left')
                sku_group['Real_Ad_Spend'] = sku_group['Real_Ad_Spend'].fillna(0)
            else:
                st.error("å¹¿å‘ŠæŠ¥è¡¨ä¸­æœªæ‰¾åˆ° 'Spend' æˆ– 'Cost' åˆ—ï¼Œæ— æ³•è®¡ç®—çœŸå®å¹¿å‘Šè´¹ã€‚")
                sku_group['Real_Ad_Spend'] = 0
        else:
            st.warning(text["warn_no_ad"])
            sku_group['Real_Ad_Spend'] = 0
        #æ€»é”€å”®é¢
        total_sales_all = sku_group['Total_Sales'].sum()
        
        # åˆ†æ‘Šæ‚è´¹
        if total_sales_all > 0:
            sku_group['Other_Share'] = (sku_group['Total_Sales'] / total_sales_all) * other_costs
        else:
            sku_group['Other_Share'] = 0
        # å¡«å……ç©ºå€¼ï¼Œé˜²æ­¢è®¡ç®—æŠ¥é”™
        sku_group = sku_group.fillna(0)

        # å‡€åˆ©æ¶¦ = æ¯›åˆ© - çœŸå®å¹¿å‘Šè´¹ - åˆ†æ‘Šæ‚è´¹
        sku_group['Net_Profit'] = sku_group['Gross_Profit'] - sku_group['Real_Ad_Spend'] - sku_group['Other_Share']

        #è®¡ç®—é”€å”®å¹¿å‘Šæ€»æˆæœ¬
        sku_group['TACOS']=sku_group.apply(lambda x: x['Real_Ad_Spend']/x['Total_Sales'] if x['Total_Sales']>0 else 0,axis=1)
        # è®¡ç®— ROAS å’Œ CVR
        sku_group['ROAS'] = sku_group.apply(lambda x: x['Total_Sales'] / x['Real_Ad_Spend'] if x['Real_Ad_Spend'] > 0 else 0, axis=1)
        sku_group['CVR'] = sku_group.apply(lambda x: x['Amount'] / x['Sessions'] if x['Sessions'] > 0 else 0,axis=1).clip(upper=1.0)
        #ç‚¹å‡»ç‡CTR
        sku_group['CTR'] = sku_group.apply(lambda x: x['Clicks'] / x['Impressions'] if x['Impressions'] > 0 else 0, axis=1)
        #è®¡ç®—æ¯›åˆ©ç‡
        sku_group['Gross_Margin'] = (sku_group['Gross_Profit'] / sku_group['Total_Sales']).fillna(0)
        #è®¡ç®—ç›ˆäºå¹³è¡¡ ROAS(BE_ROAS)
        sku_group['BE_ROAS'] = sku_group['Gross_Margin'].apply(lambda x: 1/x if x > 0 else 99.9)
        # æ±‡æ€» KPI
        revenue = sku_group['Total_Sales'].sum()
        net_profit = sku_group['Net_Profit'].sum()
        total_real_ad = sku_group['Real_Ad_Spend'].sum()
        total_storage_fee = sku_group['Storage_Total'].sum()
        quantity = sku_group['Amount'].sum()
        real_margin = net_profit / revenue if revenue > 0 else 0

        #æ™ºèƒ½åˆ†æ
        st.info(generate_summary(revenue, net_profit, real_margin,text))
        #æ ¸å¿ƒæŒ‡æ ‡å¡
        st.divider()
        c1, c2 ,c3,c4= st.columns(4)
        with c1:
            st.metric(text["metric_sales"], f"{text['sign']}{revenue:,.2f}")
        with c2:
            st.metric(text["metric_storage"], f"{text['sign']}{total_storage_fee:,.2f}")
            st.caption(text["storage_help"])
        with c3:
            st.metric(text["metric_profit"], f"{text['sign']}{net_profit:,.2f}", f"{real_margin*100:.1f}%")
        with c4:
            st.metric(text["metric_ad"], f"{text['sign']}{total_real_ad+ other_costs:,.2f}")
        
        # è°ƒç”¨ç»˜å›¾å‡½æ•°
        fig_1, fig_2 = plot_charts(filtered_df,text)
        
        # å·¦å³å¸ƒå±€å±•ç¤ºå›¾è¡¨
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(fig_1, use_container_width=True)
        with col2:
            st.plotly_chart(fig_2, use_container_width=True)
        #åº“å­˜å‘¨è½¬ç‡
        if inventory_df is not None:
            inv_simple = clean_data(inventory_df).rename(columns={
                'afn-fulfillable-quantity': 'Qty', 
                'Available': 'Qty', 
                'Quantity_Available': 'Qty'
            })[['SKU', 'Qty']].groupby('SKU')['Qty'].sum().reset_index()
        
            sku_group = pd.merge(sku_group, inv_simple, on='SKU', how='left')

            sku_group['Turnover'] = sku_group.apply(
            lambda x: x['Amount'] / x['Qty'] if (pd.notnull(x['Qty']) and x['Qty'] > 0) else 0, axis=1)
        else:
            sku_group['Turnover'] = 0

        # TOP5
        top_5 = sku_group.sort_values(by='Net_Profit', ascending=False).head(5)
        st.subheader(f"ğŸ† {period_name} {text['table_title']}")
        st.dataframe(top_5[['SKU', 'Total_Sales', 'Net_Profit', 'Amount', 'CVR','TACOS', 'Turnover','CTR']].style.format({'CTR': '{:.2%}','CVR': '{:.2%}','Total_Sales': '{:,.2f}','Net_Profit': '{:,.2f}','TACOS': '{:.1%}',
                            'Turnover': '{:.1f}'}), hide_index=True, use_container_width=True)
        csv = top_5.to_csv(index=False).encode('utf-8-sig')
        #ä¸‹è½½æ¦œå•
        st.download_button(
        label=text["download_btn"],
        data=csv,
        file_name='top_5_products.csv',
        mime='text/csv')


        #å¹¿å‘Šå¸è¡€é¬¼
        st.divider()
        st.subheader(text['vampire_title'])
        vampire_mask = (sku_group['Real_Ad_Spend'] > 0) & (sku_group['ROAS'] < sku_group['BE_ROAS'])
        vampires = sku_group[vampire_mask].sort_values(by='ROAS')
        if not vampires.empty:
            st.warning(text['vampire_help'].format(len(vampires)))
            vampire_display = vampires[['SKU', 'Total_Sales', 'Real_Ad_Spend', 'ROAS', 'BE_ROAS', 'CVR']].copy()
            vampire_display.columns  = [
                text["col_sku"], 
                text["metric_sales"], 
                text["col_ad_spend"], 
                text["roas_label"], 
                text["col_be_roas"], 
                text["metric_cvr"]
                ]
            st.dataframe(vampire_display.style.format({
                text["metric_cvr"]: '{:.2%}',
                text["col_ad_spend"]: '{:.2f}',
                text["roas_label"]: '{:.2f}',
                text["col_be_roas"]: '{:.2f}'
            }).background_gradient(subset=[text['roas_label']], cmap='Reds_r'),
              use_container_width=True, hide_index=True)
            #è´¢åŠ¡è´´å£«
            st.info(text["recommend_action"])
        else:
            if total_real_ad == 0 and adv_dfs:
                st.info(text["vampire_no_spend"])
            
            # æƒ…å†µ 2: æœ‰å¹¿å‘ŠèŠ±è´¹ï¼Œä½†ç”±äºè¡¨ç°éƒ½å¾ˆå¥½ï¼Œæ²¡æœ‰ä¸€ä¸ªæ˜¯å¸è¡€é¬¼
            elif total_real_ad > 0:
                st.success(text["vampire_safe"])
            
            # æƒ…å†µ 3: æ ¹æœ¬æ²¡ä¸Šä¼ å¹¿å‘Šè¡¨
            else:
                st.info(text["vampire_none"])
        # ==========================================
        # --- æ™ºèƒ½è¡¥è´§å»ºè®®æ¿å— ---
        # ==========================================
        st.divider()
        st.subheader(text["restock_title"])
        if inventory_df is not None:
            inventory_df = clean_data(inventory_df)
            # ã€æ–°å¢ï¼šåˆ—åæ˜ å°„ã€‘å…¼å®¹äºšé©¬é€Šå®˜æ–¹æŠ¥è¡¨å¸¸ç”¨åˆ—å
            inv_col_map = {
                'afn-fulfillable-quantity': 'Quantity_Available',
                'afn-inbound-working-quantity': 'Quantity_Inbound',
                'Available': 'Quantity_Available',
                'Fulfillable': 'Quantity_Available'
            }
            inventory_df = inventory_df.rename(columns=inv_col_map)
            required_inv_cols = ['Quantity_Available']#å¿…é¡»çš„åº“å­˜åˆ—
            if all(col in inventory_df.columns for col in required_inv_cols):#é€ä¸ªå–å‡ºæˆ‘å®šä¹‰çš„å¿…éœ€åˆ—ï¼Œåˆ¤æ–­å½“å‰çš„è¿™ä¸ªåˆ—åï¼ˆcolï¼‰ï¼Œæ˜¯å¦å­˜åœ¨äºä¸Šä¼ è¡¨æ ¼çš„åˆ—åé›†åˆï¼ˆcolumnsï¼‰é‡Œ
        
                # 1. è·å–ç›®æ ‡å¤©æ•°ï¼ˆç”¨æˆ·å¯è°ƒï¼‰
                target_days = st.number_input(text["target_days_label"], value=45, step=5)
        
                # 2. è®¡ç®—æ—¥å‡é”€é‡ (æœ€è¿‘14å¤©)
                max_date = df_sales_daily['Date'].max()#é”€å”®è¡¨æœ€åä¸€å¤©
                v_df = df_sales_daily[df_sales_daily['Date'] > (max_date - pd.Timedelta(days=14))]#æ—¶é—´åç§»é‡ï¼Œä»£è¡¨14å¤©çš„æ—¶é—´è·¨åº¦
                if not v_df.empty:
                    actual_days = v_df['Date'].nunique()
                    velocity = v_df.groupby('SKU')['Amount'].sum() / (actual_days if actual_days > 0 else 1)
                else:
                    velocity = pd.Series(0, index=df_sales_daily['SKU'].unique())
        
                # 3. åˆå¹¶æ•°æ®
                restock_df = pd.merge(inventory_df, velocity.rename('V'), on='SKU', how='left').fillna(0)
        
                # --- åŠ å…¥åœ¨é€”åº“å­˜ (Inbound) ---
                if 'Quantity_Inbound' not in restock_df.columns:
                    restock_df['Quantity_Inbound'] = 0

                # æ€»å¯ç”¨åº“å­˜ = ç°æœ‰ + åœ¨é€”
                restock_df['Total_Stock'] = restock_df['Quantity_Available'] + restock_df['Quantity_Inbound']
        
                # 4. è®¡ç®—æŒ‡æ ‡
                restock_df['Days_Left'] = restock_df.apply(lambda x: x['Total_Stock'] / x['V'] if x['V'] > 0 else 999, axis=1)
                # è¡¥è´§é‡ = (æ—¥å‡é”€é‡ * ç›®æ ‡å¤©æ•°) - æ€»å¯ç”¨åº“å­˜
                restock_df['Suggest'] = (restock_df['V'] * target_days) - restock_df['Total_Stock']
                restock_df['Suggest'] = restock_df['Suggest'].clip(lower=0).round(0)#æœ€ä½ä¹Ÿæ˜¯0å¹¶ä¸”æ˜¯æ•´æ•°
        
                # 5. ç¾åŒ–å±•ç¤º
                display_cols = ['SKU', 'Quantity_Available', 'Quantity_Inbound', 'V', 'Days_Left', 'Suggest']
                st.dataframe(
                restock_df[display_cols].sort_values('Days_Left').style.format({
                'V': '{:.2f}',         # æ—¥å‡é”€é‡ä¿ç•™2ä½å°æ•°
                'Days_Left': '{:.1f}', # å¯å”®å¤©æ•°ä¿ç•™1ä½å°æ•°
                'Suggest': '{:.0f}'    # è¡¥è´§é‡å–æ•´
                }).background_gradient(subset=['Days_Left'], # ç»™â€œå¯å”®å¤©æ•°â€è¿™ä¸€åˆ—åŠ é¢œè‰²èƒŒæ™¯
                                        cmap='RdYlGn',      # ä½¿ç”¨â€œçº¢-é»„-ç»¿â€æ¸å˜ï¼Œæ•°å€¼è¶Šå°ï¼ˆè¶Šå±é™©ï¼‰è¶Šçº¢
                                        low=0, high=0.3       # è°ƒæ•´é¢œè‰²çš„æ•æ„Ÿåº¦
                                        ),
                use_container_width=True, hide_index=True
                )
            else:
                st.error(text["error_inv_col"])
        else:
            st.info("ğŸ’¡ " + text["upload_info"])
        # ==========================================
        # --- ğŸ¨ æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨åº—é”€å”®æ¼æ–— (Sales Funnel) ---
        # ==========================================
        st.divider()
        st.subheader(text["funnel_title"]) # ä½¿ç”¨å­—å…¸æ ‡é¢˜

        # 1. å‡†å¤‡æ•°æ®
        total_impressions = sku_group['Impressions'].sum()
        total_clicks = sku_group['Clicks'].sum()
        total_sessions = sku_group['Sessions'].sum()
        total_units = sku_group['Amount'].sum()

        # 2. ç»˜åˆ¶æ¼æ–—å›¾
        fig_funnel = go.Figure(go.Funnel(
            # å…³é”®ä¿®æ”¹ï¼šç›´æ¥è¯»å–å­—å…¸é‡Œçš„åˆ—è¡¨ ["æ›å…‰é‡", "ç‚¹å‡»é‡"...]
            y = text["funnel_stages"], 
            x = [total_impressions, total_clicks, total_sessions, total_units],
            textposition = "inside",
            texttemplate = "%{value:,.0f}", # å¼ºåˆ¶æ˜¾ç¤ºå®Œæ•´æ•°å­—
            textinfo = "value+percent previous",
            opacity = 0.65, 
            marker = {"color": ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728"]}
        ))

        fig_funnel.update_layout(
            title_text=text["funnel_chart_title"], # ä½¿ç”¨å­—å…¸å›¾è¡¨æ ‡é¢˜
            height=400
        )

        st.plotly_chart(fig_funnel, use_container_width=True)

        # 3. æ™ºèƒ½è¯Šæ–­ (ä½¿ç”¨ .format æŠŠæ•°å€¼å¡«è¿›å­—å…¸çš„å¥å­åŠ›)
        if total_impressions > 0:
            ctr = total_clicks / total_impressions
            click_quality = total_sessions / total_clicks if total_clicks > 0 else 0
            cvr = total_units / total_sessions if total_sessions > 0 else 0

            st.markdown(f"#### {text['diag_title']}")
            
            # --- CTR è¯Šæ–­ ---
            if ctr < 0.003:
                st.error(text["diag_ctr_bad"].format(ctr)) # .format(ctr) ä¼šæŠŠ ctr çš„å€¼å¡«è¿› {:.2%} é‡Œ
            elif ctr > 0.01:
                st.success(text["diag_ctr_good"].format(ctr))
            else:
                st.warning(text["diag_ctr_mid"].format(ctr))
                
            # --- ç‚¹å‡»è´¨é‡è¯Šæ–­ ---
            if click_quality < 0.6: 
                st.warning(text["diag_click_bad"].format(click_quality))
            
            # --- CVR è¯Šæ–­ ---
            if cvr < 0.05:
                st.error(text["diag_cvr_bad"].format(cvr))
            elif cvr > 0.10:
                st.balloons()
                st.success(text["diag_cvr_good"].format(cvr))
            else:
                st.info(text["diag_cvr_mid"].format(cvr))       
    except Exception as e:
        st.error(f"{text['error_general']}:{e}")
else:
    st.info(text["upload_info"])


# ==========================================
# --- ğŸ”¬ SQL å®éªŒå®¤ (æ–°å¢åŠŸèƒ½) ---
# ==========================================
st.divider()
st.header("ğŸ”¬ SQL é«˜çº§å®éªŒå®¤ (DuckDBå¼•æ“)")

with st.expander("ç‚¹å‡»å±•å¼€ SQL æ§åˆ¶å°", expanded=False):
    st.markdown("""
    **è¯´æ˜**ï¼šä½ ç°åœ¨å¯ä»¥ç›´æ¥ç”¨ SQL æŸ¥è¯¢å†…å­˜ä¸­çš„ `sku_group` è¡¨ï¼ˆåŒ…å«åˆ©æ¶¦ã€ROASç­‰æ±‡æ€»æ•°æ®ï¼‰ã€‚
    è¯•è¯•è¾“å…¥ï¼š`SELECT SKU, Net_Profit FROM sku_group WHERE Net_Profit < 0`
    """)
    
    # 1. æä¾›ä¸€ä¸ªè¾“å…¥æ¡†
    default_sql = "SELECT * FROM sku_group LIMIT 5"
    sql_query = st.text_area("è¾“å…¥ä½ çš„ SQL è¯­å¥:", value=default_sql, height=150)
    
    # 2. è¿è¡ŒæŒ‰é’®
    if st.button("ğŸš€ è¿è¡Œ SQL æŸ¥è¯¢"):
        if 'sku_group' in locals():
            try:
                # --- è§è¯å¥‡è¿¹çš„æ—¶åˆ» ---
                # duckdb.query() å¯ä»¥ç›´æ¥è¯†åˆ« Python é‡Œçš„å˜é‡åï¼
                query_result = duckdb.query(sql_query).df()
                
                st.success(f"æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° {len(query_result)} æ¡è®°å½•")
                st.dataframe(query_result, use_container_width=True)
            except Exception as e:
                st.error(f"SQL è¯­æ³•é”™è¯¯: {e}")
        else:
            st.error("âŒ æ•°æ®æœªåŠ è½½ï¼Œè¯·å…ˆä¸Šä¼ æŠ¥è¡¨ï¼")
# ==========================================
# --- 3. æ–°å¢åŠŸèƒ½ï¼šå…³é”®è¯æ¡æ¼åˆ†æ (Gap Analysis) ---
# ==========================================
st.divider()
st.header("ğŸ•µï¸â€â™€ï¸ å…³é”®è¯æ¡æ¼å®éªŒå®¤ (Gap Analysis)")
st.caption("ä½¿ç”¨è¯´æ˜ï¼šè¯·ä»å–å®¶ç²¾çµå¯¼å‡ºã€å…³é”®è¯åæŸ¥ã€‘è¡¨æ ¼ï¼Œä¸Šä¼ è‡³ä¸‹æ–¹ã€‚")

# 1. åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µï¼ŒæŠŠåŠŸèƒ½åˆ†å¼€ï¼Œæ˜¾å¾—å¾ˆä¸“ä¸š
tab1, tab2 = st.tabs(["ğŸ“Š è¯é¢‘åˆ†æ (æ‰¾å±æ€§è¯)", "ğŸš€ æ¡æ¼åˆ†æ (æ‰¾è“æµ·è¯)"])

# ä¸Šä¼ ç»„ä»¶
kw_file = st.file_uploader("ä¸Šä¼ å–å®¶ç²¾çµ CSV è¡¨æ ¼", type=['csv', 'xlsx'], key="kw_uploader")

if kw_file:
    try:
        # è¯»å–æ•°æ® (å…¼å®¹ CSV å’Œ Excel)
        if kw_file.name.endswith('.csv'):
            try:
                kw_df = pd.read_csv(kw_file)
            except:
                kw_file.seek(0)
                kw_df = pd.read_csv(kw_file, encoding='gbk')
        else:
            kw_df = pd.read_excel(kw_file)
            
        # æ¸…æ´—åˆ—å (å»ç©ºæ ¼)
        kw_df.columns = [str(c).strip() for c in kw_df.columns]
        
        # è‡ªåŠ¨è¯†åˆ«â€œå…³é”®è¯â€å’Œâ€œæœç´¢é‡â€è¿™ä¸¤åˆ— (é˜²æ­¢è¡¨æ ¼æ ¼å¼ä¸ä¸€æ ·)
        # é€»è¾‘ï¼šæ‰¾åå­—é‡Œå¸¦ "Keyword" çš„åˆ—ï¼Œå’Œå¸¦ "Volume" çš„åˆ—
        col_kw = next((c for c in kw_df.columns if 'eyword' in c or 'å…³é”®è¯' in c), None)
        col_vol = next((c for c in kw_df.columns if 'olume' in c or 'æœç´¢é‡' in c), None)

        if col_kw and col_vol:
            # --- åŠŸèƒ½ A: è¯é¢‘åˆ†æ (Tab 1) ---
            with tab1:
                st.subheader("å¸‚åœºçƒ­è¯äº‘ (ä¹°å®¶æœ€çˆ±æœä»€ä¹ˆï¼Ÿ)")
                # æŠŠæ‰€æœ‰å…³é”®è¯æ‹¼åœ¨ä¸€èµ·
                all_text = " ".join(kw_df[col_kw].astype(str)).lower()
                # ç®€å•çš„åœç”¨è¯è¡¨ (å»æ‰ useless words)
                stopwords = ['for', 'in', 'the', 'and', 'with', 'of', 'to', 'a', 'mini', 'portable'] 
                words = [w for w in all_text.split() if w not in stopwords and len(w) > 2]
                
                # ç»Ÿè®¡å‰ 15 å
                from collections import Counter
                common_words = Counter(words).most_common(15)
                word_df = pd.DataFrame(common_words, columns=['çƒ­è¯', 'å‡ºç°é¢‘æ¬¡'])
                
                c1, c2 = st.columns([1, 2])
                with c1:
                    st.dataframe(word_df, use_container_width=True)
                with c2:
                    st.bar_chart(word_df.set_index('çƒ­è¯'))
                st.info("ğŸ’¡ å»ºè®®ï¼šå°†å·¦ä¾§çš„é«˜é¢‘è¯åŸ‹å…¥ä½ çš„ Listing æ ‡é¢˜æˆ–äº”ç‚¹æè¿°ä¸­ã€‚")

            # --- åŠŸèƒ½ B: æ¡æ¼åˆ†æ (Tab 2) ---
            with tab2:
                st.subheader("è“æµ·è¯æŒ–æ˜æœº")
                
                # è¾“å…¥ç«å“æ ‡é¢˜
                comp_title = st.text_area("ğŸ‘‰ ç¬¬ä¸€æ­¥ï¼šå¤åˆ¶ç«å“çš„æ ‡é¢˜åˆ°è¿™é‡Œ", 
                                        value="Anker Portable Charger, 10000mAh Power Bank (ç¤ºä¾‹)",
                                        height=70)
                
                # è®¾å®šæ¡æ¼é—¨æ§›
                min_vol = st.slider("ğŸ‘‰ ç¬¬äºŒæ­¥ï¼šè®¾å®šæœ€å°æœç´¢é‡ (å¤ªå°çš„è¯æ²¡å¿…è¦æ¡)", 100, 5000, 1000)
                
                # æŒ‰é’®è§¦å‘
                if st.button("å¼€å§‹æŒ–æ˜è“æµ·è¯"):
                    def check_gap(row):
                        k = str(row[col_kw]).lower()
                        t = comp_title.lower()
                        # æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæœç´¢é‡å¤Ÿå¤§ï¼Œä¸”æ ‡é¢˜é‡Œæ²¡è¿™ä¸ªè¯
                        if k not in t: 
                            return True
                        return False

                    # ç­›é€‰
                    mask_vol = pd.to_numeric(kw_df[col_vol], errors='coerce').fillna(0) > min_vol
                    kw_df['Is_Gap'] = kw_df.apply(check_gap, axis=1)
                    
                    gap_df = kw_df[mask_vol & kw_df['Is_Gap']].sort_values(by=col_vol, ascending=False)
                    
                    if not gap_df.empty:
                        st.success(f"âœ… æˆåŠŸå‘ç° {len(gap_df)} ä¸ªè“æµ·è¯ï¼ç«å“æ ‡é¢˜éƒ½æ²¡å†™ï¼")
                        st.dataframe(
                            gap_df[[col_kw, col_vol]].style.background_gradient(subset=[col_vol], cmap='Greens'),
                            use_container_width=True
                        )
                    else:
                        st.warning("âš ï¸ æ²¡æ‰¾åˆ°ã€‚å¯èƒ½æ˜¯ç«å“æ ‡é¢˜å†™å¾—å¤ªå…¨äº†ï¼Œæˆ–è€…ä½ è®¾å®šçš„æœç´¢é‡é—¨æ§›å¤ªé«˜ã€‚")
        else:
            st.error(f"âŒ æ— æ³•è¯†åˆ«åˆ—åã€‚è¯·ç¡®ä¿CSVé‡ŒåŒ…å«â€œKeywordâ€å’Œâ€œSearch Volumeâ€è¿™ä¸¤åˆ—ã€‚\nä½ çš„åˆ—åæ˜¯: {list(kw_df.columns)}")
            
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å‡ºé”™: {e}")